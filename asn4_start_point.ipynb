{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from geopy import distance\n",
    "import geopandas\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Simple Neural Networks\n",
    "\n",
    "For this assigment you'll do a realistic task - predicting fraud from transaction data. \n",
    "### Some Things to Note\n",
    "\n",
    "<ul>\n",
    "<li> The dataset is imbalanced. See: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data for some ideas\n",
    "<li> The locations, time, dob all likely aren't super useful on their own, but can be made into something more useful without much code or trouble. Think about how it may be useful to represent them. The data doesn't have missing rows, so this is the main data prep portion. \n",
    "<li> With respect to the above, and the other data here, we have a lot of rows of data. That means that we can generally handle data that is reasonably wide...\n",
    "</ul>\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "Your final goal is to produce a function that can be called to classify a transaction:\n",
    "<ul>\n",
    "<li> Please submit two .ipynb files - one where you did your work, and another that can use your model to make predictions. \n",
    "<li> In that prediction file, please ensure:\n",
    "    <ul>\n",
    "    <li> You have a function where I can load a file, and the end result is a classificaiton matrix of your prediction accuracy. \n",
    "    <li> You load a trained model. There's no training here. \n",
    "    <li> Any data prep stuff that is needed for your data should be built in here. I'm going to run a test file that is the exact same setup as the training data.\n",
    "    <li> I should be able to open the prediction file, load the test data, and click RUN ALL and things should work. \n",
    "    <li> In addition to that, please include a short (~1-2 paragraph) description of what you did. Include anything that was innovative/different as well as a note on:\n",
    "        <ul>\n",
    "        <li> Any imbalanced data steps. \n",
    "        <li> Treatment of the location and time variables. What did you do to them?\n",
    "        <li> Model structure (layers/size)\n",
    "        <li> Any optimization steps included - regularization, dropouts, feature selection, etc...\n",
    "        </ul>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "### Grades\n",
    "\n",
    "The grade breakdown is as follows:\n",
    "\n",
    "<ul>\n",
    "<li> Code preduces predictions - 40\n",
    "<li> Accuracy - 30\n",
    "<li> Explaination - 20\n",
    "<li> Balance/variable transformations - 10\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fraudTrain.csv.zip\")\n",
    "df.drop(columns={\"Unnamed: 0\"}, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Lat/Lon\n",
    "\n",
    "We can utilize lat/lon of the home and merchant in a useful way?\n",
    "\n",
    "Note: I left the section headers in from when I did it. You can remove them if you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Time\n",
    "\n",
    "Can we make date/time and the date of birth into something useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Target Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml3950')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
